# This weight file is generated by BP (Erhan Oztop -Dec'99)
# This file specfies the network size and the weight values
# That the network sizes excludes the clamped 1's for input and hidden layer
# So the weight matrices has one more column for the clamped unit.

# Note: To train the network you need to load a pattern file
# Note: You can not specify learning parameters from this file
# Note: If you want to continue a learning session that you saved the 
# weights from, use Make Network from Weight followed by Load Pattern then continue training.

# First matrix is the input(x)->hidden(y) weights(inputToHiddenW) 
# Second matrix is the hidden(y)->output(z) weights(hiddenToOutputW) 
# The network computes  sgn(hiddenToOutputW.sgn(inputToHiddenW.x)) where sgn(t)=1/(1+exp(-t))

outputdim  3
hiddendim  20
inputdim   14

#input  -> hidden weights  inputToHiddenW[20][14]
11.879860154936782 0.5071037554510124 -9.903993798177519 -3.8634253627624555 2.4277769492159247 -5.193820629374679 4.676779359541241 -4.038359568261132 0.22095318649694096 0.577944187602221 -2.1377518352621063 2.936041466864347 -4.288213991359075 1.1075361548312972 
-0.9229877648650546 -2.287241099399311 -2.268696699292216 -1.7493431049605084 3.779015376515624 3.9556273432013103 -2.757119625783644 -2.3044910927185427 2.2105903388479238 2.3190116787439345 0.7918596037592925 2.538015684179756 -0.6012304106822066 -6.439107383475306 
-1.4400259651360088 -4.576246442121501 -1.945231708540373 3.893817261778922 16.767795565436113 0.9383436685052513 -1.2177010039253864 -11.078063537191925 -2.6582078363751953 -2.734609651727135 -8.259251097089107 10.495445626577226 -6.775388993370749 -5.945894005230896 
10.325289159660544 17.27811905347824 -5.847449809450898 -2.8994072055049043 -2.534513199209834 -0.8608605015399896 -2.6889013917302806 -3.2200628021459448 -3.7947414891688207 -3.890521852807562 -1.8836945105781282 0.06589483278152164 3.8009060562771513 -4.310310423111727 
-0.848964347405045 3.7025372365028026 9.175509525862216 -3.123815822705808 2.747343402651342 0.9974114464528366 1.1070931639727264 -24.120936754110524 11.390034871688066 7.118921893849496 -18.783124181686883 -28.66875137781594 7.150115385361502 28.520951351710877 
-0.31814133285026863 -4.109940048744413 -5.951055838777059 5.381316117228461 -3.3510124646943207 -0.8827386209314282 0.6299024799360766 31.285724882681382 -18.38167982536089 -16.577102482192267 17.10217188683103 23.894939932386485 -26.320341002103646 -7.305431378518986 
0.5587163535891665 7.2558894596956 5.38049405979988 11.278224919090103 0.28580189734535466 0.7101396355919258 1.0277655531462884 -2.0569692402294715 -2.165603530172882 -1.0477442448060106 -2.383520314447731 28.044228783740177 -27.510372261067175 -2.0064050872169794 
2.753336232794997 -2.6643114659726383 -5.489280506485499 11.226024884259644 0.8394514224613341 2.333426736827776 -3.18139767095219 0.20431042166543412 0.9664091773758702 0.7603385774567443 -0.02749629515681055 -0.6899620736507486 -2.739142423465778 -4.234556594958947 
0.5880760655789259 1.4846299903102724 -1.0288096952343075 -1.1779313993334741 -0.5118641156241319 0.05334130851098549 0.20474832063008688 -0.7786862698965052 -1.079324269367567 -1.0250929905603394 -0.5056452563454837 -0.02653547153022974 -0.5706332095020188 -1.145474612590925 
-1.488799641854221 7.953763846941766 2.537905723821827 3.1490458374923787 9.85898989278516 -2.3855649788854065 7.802497601271955 -7.526400184024155 -6.725093109890162 -6.648817581689548 -7.224147794623408 -3.445574625469742 5.387026354697167 2.4404488841938234 
-5.020221800071811 -2.2576061840653874 0.14134475026633933 -3.3632604037135243 2.6677895646337957 1.2123139828082918 -10.828684756556036 -0.30168356418087827 0.4189666048910497 0.5719955931457508 -0.02776589592964018 2.1927856606047147 1.467850410458702 -3.3718811092312295 
4.978309658131192 0.45782966429283717 1.339737982300851 7.973649702160478 0.5258889757671799 5.11162728434872 3.0587784378066285 -1.1415763613205339 -1.0966657567820584 -1.4708068521032347 -2.2381484077480627 -1.7606935352928506 -2.2814246253885235 -1.9561706445595701 
2.2145068636454894 3.090515206544146 -4.101928943091399 -3.995736357806311 2.990201373305705 0.8932178282595165 3.2792926660470894 -0.5987307331098043 -1.3877220718590488 -1.1529437927876158 -0.0998004988532666 0.7774531415154917 0.21791394718523333 -0.6474826426716734 
-0.31492208295925844 -1.8726036689096743 -0.9780986520168791 0.38041502798312743 7.7171433185001055 -7.516626731283814 5.7716805392555655 -5.4381718973151285 -1.541412882370186 -1.540307731435558 -3.773369149865069 6.360565398587003 -2.457055952881609 -2.8460894551247025 
5.739270386153899 -5.2638705193941115 -4.576643701089906 -7.981531029074895 3.6137283620350416 -16.091930455877513 10.25889895407734 -2.280948513593189 5.648567019942262 4.924188109355467 -0.6753949407569119 4.08192369123277 -5.120973370686937 2.71354192919878 
-2.5969602925450825 7.385907126507911 -2.003157004334575 1.4887932232179673 0.9844378775278597 -8.515735933377064 -2.4013432165218362 -1.7406425041898048 0.49932181083638405 0.6122872633612906 -1.5529501504576244 1.6407576287995833 0.6594627170100936 2.269096118461321 
1.5509553033033208 4.189782426436547 -1.5023933620634857 -3.1018503741886603 4.42475377795377 -0.22619333142268574 3.5479870005366134 -8.177577966669885 1.9238359672830807 2.1689376237411366 -3.96442568552585 16.724710872261422 -14.56835755934515 -8.620375905495186 
0.5957385372860323 11.758373178280792 -2.3474366156983564 -2.185727857768919 0.8762869547175468 2.7188286499333523 -1.9641036571783932 -8.531801029587584 0.5488435357650133 0.09480240781750195 -4.992820266311313 6.305229335247776 -4.10880482116905 -2.3524997152949836 
-2.581612022766396 -2.6555214366889452 4.06495819748642 -4.206132939903084 3.9683435455122673 8.414295295034929 0.005842826745272853 -11.760657060465668 2.700565685152742 2.2097249499475753 -6.103983390492497 -2.719942171879307 0.9755605253175691 -4.353609431423492 
-9.039137681359724 -21.573593851016692 6.760560114771421 5.488456923171793 2.195771730800478 -0.5758359025730357 3.559041033530964 -2.540702928331143 3.055206989244932 3.0101846763223232 0.09540350690753675 15.236310020931922 -2.861540171070262 -5.178778974113215 

#hidden -> output weights  hiddenToOutputW[3][20]:
0.3327944476489058 -3.2796645735371337 -5.171704479986748 -1.2296274015959316 -15.346399238814865 -27.83686253057685 14.56422320485028 -9.777917227235495 -0.8426947729529087 7.993795307126344 -8.312677658877819 -2.3658866704978534 0.40805122167965746 0.4101898158744967 -7.167153983652719 -1.33939868832962 -16.709359476693958 -3.4892415369276075 -8.986553037297005 -16.422639137695576 
-4.828101552160882 -0.269517806166272 -11.529594881376477 -13.33092339112477 -13.074586196251417 -14.957942835972311 14.881514882029935 -4.20501283424647 -1.7814319751112038 1.447115484730042 -1.1285131633373777 -0.09735836670415153 -3.9511493929413053 3.901464205104758 1.0779744207517579 -5.462865089553226 -7.261290009687381 -10.211976592418413 -5.9190744966110245 -0.27494311128185633 
6.3472149456689895 4.466042015794045 -9.088463874371811 -5.969197105328502 -27.40073113016672 -16.028066128999708 6.201183394624199 6.104571326473172 -0.8600600349250458 -3.702620004333258 -0.12533299294848177 -7.985312362017075 0.14331525971350378 -8.999833827710757 7.982727549685876 -6.327860171742678 -0.07469354951826168 -2.8067287697629695 -0.8228337237284988 -9.761928297390364 
