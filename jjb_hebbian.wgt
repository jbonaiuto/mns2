# This weight file is generated by Hebbian
# This file specfies the network size and the weight values

# Note: To train the network you need to load a pattern file
# Note: You can not specify learning parameters from this file
# Note: If you want to continue a learning session that you saved the
# weights from, use Make net.Network from Weight followed by Load Pattern then continue training.

# First matrix is the input(x)->hidden(y) weights(inputToHiddenW)
# Second matrix is the hidden(x)->output(y) weights(hiddenToOutputW)
# Third matrix is the teacher(y)->output(z) weights(teacherToOutputW)
outputLayerDim  9
hiddenLayerDim  15
teacherdim  3
inputLayerDim   14

#input  -> hidden weights  inputToHiddenW[15][14]
-0.0584841891890766 -0.05849164689003164 -0.05840037673383495 -0.05685758910599543 -0.05817318881059763 -0.05849698509463997 -0.05851292850847657 -0.2429518880768401 -0.23447818671331405 0.11498160496774404 0.2621031848353688 0.0830327785184271 -0.18125352323553404 -0.1374828463994084 
0.0687122860360642 0.06871042161082545 0.06873323914987457 0.06911893605683446 0.06879003613068395 0.06870908705967332 0.0687051012062142 0.022595361314123284 0.02471378665500485 -0.05458793209139729 -0.017807537124491138 -0.06257513870372657 0.038019952524449854 0.048962621733481246 
-0.0584841891890766 -0.05849164689003164 -0.05840037673383495 -0.05685758910599543 -0.05817318881059763 -0.05849698509463997 -0.05851292850847657 -0.2429518880768401 -0.23447818671331405 0.11498160496774404 0.2621031848353688 0.0830327785184271 -0.18125352323553404 -0.1374828463994084 
0.0687122860360642 0.06871042161082545 0.06873323914987457 0.06911893605683446 0.06879003613068395 0.06870908705967332 0.0687051012062142 0.022595361314123284 0.02471378665500485 -0.05458793209139729 -0.017807537124491138 -0.06257513870372657 0.038019952524449854 0.048962621733481246 
-0.0584841891890766 -0.05849164689003164 -0.05840037673383495 -0.05685758910599543 -0.05817318881059763 -0.05849698509463997 -0.05851292850847657 -0.2429518880768401 -0.23447818671331405 0.11498160496774404 0.2621031848353688 0.0830327785184271 -0.18125352323553404 -0.1374828463994084 
0.0687122860360642 0.06871042161082545 0.06873323914987457 0.06911893605683446 0.06879003613068395 0.06870908705967332 0.0687051012062142 0.022595361314123284 0.02471378665500485 -0.05458793209139729 -0.017807537124491138 -0.06257513870372657 0.038019952524449854 0.048962621733481246 
0.0687122860360642 0.06871042161082545 0.06873323914987457 0.06911893605683446 0.06879003613068395 0.06870908705967332 0.0687051012062142 0.022595361314123284 0.02471378665500485 -0.05458793209139729 -0.017807537124491138 -0.06257513870372657 0.038019952524449854 0.048962621733481246 
0.0687122860360642 0.06871042161082545 0.06873323914987457 0.06911893605683446 0.06879003613068395 0.06870908705967332 0.0687051012062142 0.022595361314123284 0.02471378665500485 -0.05458793209139729 -0.017807537124491138 -0.06257513870372657 0.038019952524449854 0.048962621733481246 
0.0687122860360642 0.06871042161082545 0.06873323914987457 0.06911893605683446 0.06879003613068395 0.06870908705967332 0.0687051012062142 0.022595361314123284 0.02471378665500485 -0.05458793209139729 -0.017807537124491138 -0.06257513870372657 0.038019952524449854 0.048962621733481246 
0.0687122860360642 0.06871042161082545 0.06873323914987457 0.06911893605683446 0.06879003613068395 0.06870908705967332 0.0687051012062142 0.022595361314123284 0.02471378665500485 -0.05458793209139729 -0.017807537124491138 -0.06257513870372657 0.038019952524449854 0.048962621733481246 
0.0687122860360642 0.06871042161082545 0.06873323914987457 0.06911893605683446 0.06879003613068395 0.06870908705967332 0.0687051012062142 0.022595361314123284 0.02471378665500485 -0.05458793209139729 -0.017807537124491138 -0.06257513870372657 0.038019952524449854 0.048962621733481246 
0.0687122860360642 0.06871042161082545 0.06873323914987457 0.06911893605683446 0.06879003613068395 0.06870908705967332 0.0687051012062142 0.022595361314123284 0.02471378665500485 -0.05458793209139729 -0.017807537124491138 -0.06257513870372657 0.038019952524449854 0.048962621733481246 
0.0687122860360642 0.06871042161082545 0.06873323914987457 0.06911893605683446 0.06879003613068395 0.06870908705967332 0.0687051012062142 0.022595361314123284 0.02471378665500485 -0.05458793209139729 -0.017807537124491138 -0.06257513870372657 0.038019952524449854 0.048962621733481246 
0.0687122860360642 0.06871042161082545 0.06873323914987457 0.06911893605683446 0.06879003613068395 0.06870908705967332 0.0687051012062142 0.022595361314123284 0.02471378665500485 -0.05458793209139729 -0.017807537124491138 -0.06257513870372657 0.038019952524449854 0.048962621733481246 
0.0687122860360642 0.06871042161082545 0.06873323914987457 0.06911893605683446 0.06879003613068395 0.06870908705967332 0.0687051012062142 0.022595361314123284 0.02471378665500485 -0.05458793209139729 -0.017807537124491138 -0.06257513870372657 0.038019952524449854 0.048962621733481246 
#hidden  -> output weights  hiddenToOutputW[9][15]
-0.08334079836530175 -0.083335416701688 -0.08334079836530175 -0.083335416701688 -0.08334079836530175 -0.083335416701688 -0.083335416701688 -0.083335416701688 -0.083335416701688 -0.083335416701688 -0.083335416701688 -0.083335416701688 -0.083335416701688 -0.083335416701688 -0.083335416701688 
-0.08334079836530175 -0.083335416701688 -0.08334079836530175 -0.083335416701688 -0.08334079836530175 -0.083335416701688 -0.083335416701688 -0.083335416701688 -0.083335416701688 -0.083335416701688 -0.083335416701688 -0.083335416701688 -0.083335416701688 -0.083335416701688 -0.083335416701688 
-0.08334079836530175 -0.083335416701688 -0.08334079836530175 -0.083335416701688 -0.08334079836530175 -0.083335416701688 -0.083335416701688 -0.083335416701688 -0.083335416701688 -0.083335416701688 -0.083335416701688 -0.083335416701688 -0.083335416701688 -0.083335416701688 -0.083335416701688 
0.16665059484790268 0.1666613581505513 0.16665059484790268 0.1666613581505513 0.16665059484790268 0.1666613581505513 0.1666613581505513 0.1666613581505513 0.1666613581505513 0.1666613581505513 0.1666613581505513 0.1666613581505513 0.1666613581505513 0.1666613581505513 0.1666613581505513 
-0.08334079836530175 -0.083335416701688 -0.08334079836530175 -0.083335416701688 -0.08334079836530175 -0.083335416701688 -0.083335416701688 -0.083335416701688 -0.083335416701688 -0.083335416701688 -0.083335416701688 -0.083335416701688 -0.083335416701688 -0.083335416701688 -0.083335416701688 
0.1666524755035842 0.16666323884671827 0.1666524755035842 0.16666323884671827 0.1666524755035842 0.16666323884671827 0.16666323884671827 0.16666323884671827 0.16666323884671827 0.16666323884671827 0.16666323884671827 0.16666323884671827 0.16666323884671827 0.16666323884671827 0.16666323884671827 
-0.08334079836530175 -0.083335416701688 -0.08334079836530175 -0.083335416701688 -0.08334079836530175 -0.083335416701688 -0.083335416701688 -0.083335416701688 -0.083335416701688 -0.083335416701688 -0.083335416701688 -0.083335416701688 -0.083335416701688 -0.083335416701688 -0.083335416701688 
-0.08334079836530175 -0.083335416701688 -0.08334079836530175 -0.083335416701688 -0.08334079836530175 -0.083335416701688 -0.083335416701688 -0.083335416701688 -0.083335416701688 -0.083335416701688 -0.083335416701688 -0.083335416701688 -0.083335416701688 -0.083335416701688 -0.083335416701688 
0.1666521394567026 0.16666290279260246 0.1666521394567026 0.16666290279260246 0.1666521394567026 0.16666290279260246 0.16666290279260246 0.16666290279260246 0.16666290279260246 0.16666290279260246 0.16666290279260246 0.16666290279260246 0.16666290279260246 0.16666290279260246 0.16666290279260246 

#teacher -> output weights  teacherToOutputW[9][3]:
0.0 11.578787151429218 0.0 
0.0 14.051195898844743 0.0 
0.0 12.489018377657551 0.0 
0.0 0.0 10.971692171072151 
14.45159117673851 0.0 0.0 
0.0 0.0 12.041102195428994 
12.078069932616703 0.0 0.0 
11.474182877171222 0.0 0.0 
0.0 0.0 11.74698502995787 
